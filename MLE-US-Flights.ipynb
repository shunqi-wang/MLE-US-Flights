{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34cc1ed-1b34-4afb-8135-543930d69fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "import json\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62014471-242f-4d0a-a8cd-1f9139955a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-836402295281\n"
     ]
    }
   ],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6b0b11-6c94-4833-abc8-e2d81d6edc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PREFIX: GROUP6/data/\n",
      "PIPELINE_NAME: GROUP6-pipeline\n",
      "MODEL_PACKAGE_GROUP_NAME: GROUP6-ModelPackageGroup\n"
     ]
    }
   ],
   "source": [
    "GROUP_NAME = 'GROUP6' # CHANGE THIS TO YOUR FIRST NAME\n",
    "S3_PATH = f's3://{bucket}/' # S3 path prefix\n",
    "DATA_PREFIX = f'{GROUP_NAME}/data/' # S3 prefix to store data\n",
    "MODEL_PREFIX = f'{GROUP_NAME}/model/' # S3 prefix to store the XGBoost training information and model.\n",
    "\n",
    "BASE_JOB_PROCESSING_NAME = f'{GROUP_NAME}-processing'  # base_job_name for preprocessing\n",
    "BASE_JOB_TRAINING_NAME = f'{GROUP_NAME}-training'  # base_job_name for training\n",
    "BASE_JOB_EVALUATION_NAME = f'{GROUP_NAME}-evaluation'  # base_job_name for evaluation\n",
    "\n",
    "PIPELINE_NAME = f'{GROUP_NAME}-pipeline'  # SageMaker Pipeline name\n",
    "MODEL_PACKAGE_GROUP_NAME = f'{GROUP_NAME}-ModelPackageGroup'  # Model package group name in the Model Registry\n",
    "\n",
    "print(f'DATA_PREFIX: {DATA_PREFIX}')\n",
    "print(f'PIPELINE_NAME: {PIPELINE_NAME}')\n",
    "print(f'MODEL_PACKAGE_GROUP_NAME: {MODEL_PACKAGE_GROUP_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e63d4e4-aec1-4347-abc7-61522f81ab3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "# Define initial parameters\n",
    "input_data_path1 = f'{DATA_PREFIX}/US_flights_2023.csv'\n",
    "input_data_path2 = f'{DATA_PREFIX}/airports_geolocation.csv'\n",
    "input_data_path3 = f'{DATA_PREFIX}/weather_meteo_by_airport.csv'\n",
    "\n",
    "# raw input data\n",
    "input_data1 = ParameterString(name=\"InputData1\", default_value=input_data_path1)\n",
    "input_data2 = ParameterString(name=\"InputData2\", default_value=input_data_path2)\n",
    "input_data3 = ParameterString(name=\"InputData3\", default_value=input_data_path3)\n",
    "\n",
    "# status of newly trained model in registry\n",
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=\"Approved\")\n",
    "\n",
    "# processing step parameters\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "\n",
    "# training step parameters\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "training_instance_count = ParameterInteger(name=\"TrainingInstanceCount\", default_value=1)\n",
    "\n",
    "# model performance step parameters\n",
    "accuracy_rmse_threshold = ParameterFloat(name=\"AccuracyRMSEThreshold\", default_value=60.0)\n",
    "\n",
    "# SKLearn version to use\n",
    "sklearn_framework_version = \"1.2-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554931a3-7a68-41d9-9953-1865551f51aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-836402295281/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_bucket_path = 's3://' + sagemaker.Session().default_bucket() + '/'\n",
    "\n",
    "s3_bucket_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bb94a6-996f-422f-a588-0f51d415f92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the local paths to your files and the S3 prefix (directory) to upload to\n",
    "files = ['US_flights_2023.csv', 'airports_geolocation.csv', 'weather_meteo_by_airport.csv']\n",
    "\n",
    "# Upload files to S3\n",
    "for file in files:\n",
    "    sagemaker_session.upload_data(path=file, key_prefix=DATA_PREFIX)\n",
    "    \n",
    "# Specify the paths to your uploaded files\n",
    "file_paths = [f'{DATA_PREFIX}/US_flights_2023.csv', f'{DATA_PREFIX}/airports_geolocation.csv', f'{DATA_PREFIX}/weather_meteo_by_airport.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e58a4aba-de80-408e-8ad1-258de47a6bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download test.csv for local testing\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket,'GROUP6/data/test.csv','test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ea961-4a15-4612-a3b7-cfe6314d7178",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49114b7-1873-4207-bebe-8322d72a50d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocess.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tarfile\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers.beta.framework import (\n",
    "        content_types,\n",
    "        encoders,\n",
    "        env,\n",
    "        modules,\n",
    "        transformer,\n",
    "        worker,\n",
    "        server,\n",
    "    )\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "RANDOM_STATE = 2024\n",
    "LABEL_COLUMN = 'Dep_Delay'\n",
    "feature_columns = ['Day_Of_Week', 'Airline', 'Dep_Airport', 'Dep_CityName', 'DepTime_label', 'Distance_type', 'Manufacturer', 'Model', 'Aicraft_age',\n",
    "                   'STATE', 'LATITUDE', 'LONGITUDE', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'pres', 'FlightMonth']\n",
    "\n",
    "one_hot_columns = ['Day_Of_Week', 'Airline', 'Dep_Airport', 'Dep_CityName', 'DepTime_label', 'Distance_type', 'Manufacturer', 'Model', 'STATE', 'FlightMonth']\n",
    "non_one_hot_columns = ['Aicraft_age', 'LATITUDE', 'LONGITUDE', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'pres']\n",
    "\n",
    "base_dir = \"/opt/ml/processing\"\n",
    "base_output_dir = \"/opt/ml/processing/output/\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.debug(\"Starting preprocessing script\")\n",
    "\n",
    "    # Define the input data path within the processing environment\n",
    "    input_data_path1 = f'{base_dir}/input/US_flights_2023.csv'\n",
    "    input_data_path2 = f'{base_dir}/input/airports_geolocation.csv'\n",
    "    input_data_path3 = f'{base_dir}/input/weather_meteo_by_airport.csv'\n",
    "    \n",
    "    # Read the CSV file from the input path\n",
    "    logger.debug(\"Reading input data\")\n",
    "    df1 = pd.read_csv(input_data_path1)\n",
    "    df2 = pd.read_csv(input_data_path2)\n",
    "    df3 = pd.read_csv(input_data_path3)\n",
    "    \n",
    "    # Sample the data to reduce size (e.g., take a 2% sample)\n",
    "    logger.debug(\"Sampling data to reduce size\")\n",
    "    df1_sample = df1.sample(frac=0.02, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Merge sampled data\n",
    "    logger.debug(\"Merging dataframes\")\n",
    "    merged_df = pd.merge(df1_sample, df2, left_on='Dep_Airport', right_on='IATA_CODE', how='left')\n",
    "    \n",
    "    merged_df['FlightDate'] = pd.to_datetime(merged_df['FlightDate'])\n",
    "    df3['time'] = pd.to_datetime(df3['time'])\n",
    "    merged_df['FlightMonth'] = merged_df['FlightDate'].dt.month\n",
    "    \n",
    "    df = pd.merge(merged_df, df3, left_on=['Dep_Airport', 'FlightDate'], right_on=['airport_id', 'time'], how='left')\n",
    "\n",
    "    # Include only relevant columns in feature_data\n",
    "    feature_data = df[feature_columns]\n",
    "    label_data = df[LABEL_COLUMN]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('onehot', OneHotEncoder(), one_hot_columns),\n",
    "            ('scaler', StandardScaler(), non_one_hot_columns)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    logger.debug(\"Applying transformations to the data\")\n",
    "    feature_data_transformed = preprocessor.fit_transform(feature_data)\n",
    "\n",
    "    # Ensure transformed features have correct shape\n",
    "    logger.debug(f\"Transformed feature shape: {feature_data_transformed.shape}\")\n",
    "\n",
    "    logger.debug(\"Splitting data into train, validation, and test sets\")\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(feature_data_transformed, label_data, test_size=0.2, random_state=42)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Ensure y arrays are 2D\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    y_val = y_val.values.reshape(-1, 1)\n",
    "    y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "    # Verify the shapes\n",
    "    logger.debug(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    logger.debug(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    logger.debug(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    # Print a few rows of each to verify\n",
    "    logger.debug(f\"First 5 rows of x_train: {x_train[:5]}\")\n",
    "    logger.debug(f\"First 5 rows of y_train: {y_train[:5]}\")\n",
    "    \n",
    "    logger.debug(\"Combining features and labels\")\n",
    "    train_dataset = pd.DataFrame(np.hstack((y_train, x_train.toarray())))\n",
    "    val_dataset = pd.DataFrame(np.hstack((y_val, x_val.toarray())))\n",
    "    test_dataset = pd.DataFrame(np.hstack((y_test, x_test.toarray())))\n",
    "\n",
    "    # Get feature columns after transformation\n",
    "    transformed_feature_columns = preprocessor.get_feature_names_out()\n",
    "\n",
    "    train_dataset.columns = [LABEL_COLUMN] + list(transformed_feature_columns)\n",
    "    val_dataset.columns = [LABEL_COLUMN] + list(transformed_feature_columns)\n",
    "    test_dataset.columns = [LABEL_COLUMN] + list(transformed_feature_columns)\n",
    "    \n",
    "    logger.debug(\"Creating output directories if they don't exist\")\n",
    "    os.makedirs(f'{base_output_dir}train', exist_ok=True)\n",
    "    os.makedirs(f'{base_output_dir}validation', exist_ok=True)\n",
    "    os.makedirs(f'{base_output_dir}test', exist_ok=True)\n",
    "    os.makedirs(f'{base_output_dir}preprocessor', exist_ok=True)\n",
    "\n",
    "    logger.debug(\"Saving datasets to CSV\")\n",
    "    train_dataset.to_csv(f'{base_output_dir}train/train.csv', header=False, index=False)\n",
    "    val_dataset.to_csv(f'{base_output_dir}validation/validation.csv', header=False, index=False)\n",
    "    test_dataset.to_csv(f'{base_output_dir}test/test.csv', header=False, index=False)\n",
    "\n",
    "    logger.debug(\"Saving preprocessor model\")\n",
    "    joblib.dump(preprocessor, f'{base_output_dir}preprocessor/preprocessor.joblib')\n",
    "    \n",
    "    with tarfile.open(f'{base_output_dir}preprocessor/preprocessor.tar.gz', 'w:gz') as tar_handle:\n",
    "        tar_handle.add(f'{base_output_dir}preprocessor/preprocessor.joblib', arcname='preprocessor.joblib')\n",
    "\n",
    "    logger.debug(\"Preprocessing script completed successfully\")\n",
    "\n",
    "def input_fn(input_data, content_type):\n",
    "    if content_type == \"text/csv\":\n",
    "        df = pd.read_csv(StringIO(input_data), header=None)\n",
    "        df.columns = transformed_feature_columns if len(df.columns) == len(transformed_feature_columns) else [LABEL_COLUMN] + transformed_feature_columns\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    if accept == \"application/json\":\n",
    "        instances = [row.tolist() for row in prediction]\n",
    "        json_output = {\"instances\": instances}\n",
    "        return worker.Response(json.dumps(json_output), mimetype=accept)\n",
    "    elif accept == \"text/csv\":\n",
    "        return worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
    "    else:\n",
    "        print(f\"Warning: {accept} accept type is not supported by this script. Defaulting to text/csv.\")\n",
    "        return worker.Response(encoders.encode(prediction, \"text/csv\"), mimetype=\"text/csv\")\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    features = model.transform(input_data)\n",
    "    if LABEL_COLUMN in input_data:\n",
    "        return np.insert(features, 0, input_data[LABEL_COLUMN], axis=1)\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"preprocessor.joblib\"))\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b1670b8-5a55-4af9-abc9-2511476a35e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2024-06-20-13-18-29-805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Starting preprocessing script\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Reading input data\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Sampling data to reduce size\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Merging dataframes\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Applying transformations to the data\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Transformed feature shape: (134868, 813)\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Splitting data into train, validation, and test sets\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:x_train shape: (107894, 813), y_train shape: (107894, 1)\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:x_val shape: (13487, 813), y_val shape: (13487, 1)\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:x_test shape: (13487, 813), y_test shape: (13487, 1)\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:First 5 rows of x_train:   (0, 2)#0111.0\n",
      "  (0, 18)#0111.0\n",
      "  (0, 120)#0111.0\n",
      "  (0, 452)#0111.0\n",
      "  (0, 706)#0111.0\n",
      "  (0, 712)#0111.0\n",
      "  (0, 715)#0111.0\n",
      "  (0, 735)#0111.0\n",
      "  (0, 758)#0111.0\n",
      "  (0, 790)#0111.0\n",
      "  (0, 802)#0111.3382639788382422\n",
      "  (0, 803)#0110.9354451863275371\n",
      "  (0, 804)#0110.6107843705632091\n",
      "  (0, 805)#011-1.5441207139515607\n",
      "  (0, 806)#011-1.5304910426989742\n",
      "  (0, 807)#011-1.537306431503668\n",
      "  (0, 808)#011-0.3102885541305497\n",
      "  (0, 809)#011-0.10305920589366487\n",
      "  (0, 810)#011-0.9273100159154994\n",
      "  (0, 811)#011-0.7543689071537133\n",
      "  (0, 812)#011-0.3567476055656604\n",
      "  (1, 5)#0111.0\n",
      "  (1, 18)#0111.0\n",
      "  (1, 112)#0111.0\n",
      "  (1, 444)#0111.0\n",
      "  :#011:\n",
      "  (3, 809)#011-0.10305920589366487\n",
      "  (3, 810)#0111.2079073116158328\n",
      "  (3, 811)#0111.6223388542989607\n",
      "  (3, 812)#0111.496072009042129\n",
      "  (4, 6)#0111.0\n",
      "  (4, 9)#0111.0\n",
      "  (4, 35)#0111.0\n",
      "  (4, 372)#0111.0\n",
      "  (4, 708)#0111.0\n",
      "  (4, 712)#0111.0\n",
      "  (4, 713)#0111.0\n",
      "  (4, 731)#0111.0\n",
      "  (4, 770)#0111.0\n",
      "  (4, 797)#0111.0\n",
      "  (4, 802)#0111.4652862448411783\n",
      "  (4, 803)#0111.0246551016641487\n",
      "  (4, 804)#0111.11834693632953\n",
      "  (4, 805)#0110.574826195765108\n",
      "  (4, 806)#0110.6160806791468639\n",
      "  (4, 807)#0110.4936966705189221\n",
      "  (4, 808)#0111.2642502943117704\n",
      "  (4, 809)#011-0.10305920589366487\n",
      "  (4, 810)#0110.6606457276687266\n",
      "  (4, 811)#011-0.15132365424781097\n",
      "  (4, 812)#011-0.7081444290257684\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:First 5 rows of y_train: [[-4]\n",
      " [-2]\n",
      " [-2]\n",
      " [-9]\n",
      " [-3]]\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Combining features and labels\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Creating output directories if they don't exist\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Saving datasets to CSV\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Saving preprocessor model\u001b[0m\n",
      "\u001b[34mDEBUG:__main__:Preprocessing script completed successfully\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version='1.2-1',\n",
    "    role=role,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    instance_count=1 \n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code=\"code/preprocess.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=S3_PATH + DATA_PREFIX,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"scaler_model\",\n",
    "            source=\"/opt/ml/processing/output/preprocessor\",\n",
    "            destination=S3_PATH + MODEL_PREFIX\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=S3_PATH + DATA_PREFIX\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/output/validation\",\n",
    "            destination=S3_PATH + DATA_PREFIX\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination=S3_PATH + DATA_PREFIX\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a29eb0c-e898-40c1-b97f-5f7a2e8fb678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'input-1',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-202646161072/GROUP6/data/',\n",
       "    'LocalPath': '/opt/ml/processing/input',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'code',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-202646161072/sagemaker-scikit-learn-2024-06-20-02-35-30-277/input/code/preprocess.py',\n",
       "    'LocalPath': '/opt/ml/processing/input/code',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'scaler_model',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-202646161072/GROUP6/model/',\n",
       "     'LocalPath': '/opt/ml/processing/output/preprocessor',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False},\n",
       "   {'OutputName': 'train',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-202646161072/GROUP6/data/',\n",
       "     'LocalPath': '/opt/ml/processing/output/train',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False},\n",
       "   {'OutputName': 'validation',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-202646161072/GROUP6/data/',\n",
       "     'LocalPath': '/opt/ml/processing/output/validation',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False},\n",
       "   {'OutputName': 'test',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-202646161072/GROUP6/data/',\n",
       "     'LocalPath': '/opt/ml/processing/output/test',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False}]},\n",
       " 'ProcessingJobName': 'sagemaker-scikit-learn-2024-06-20-02-35-30-277',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
       "   'InstanceType': 'ml.c5.xlarge',\n",
       "   'VolumeSizeInGB': 30}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "  'ContainerEntrypoint': ['python3',\n",
       "   '/opt/ml/processing/input/code/preprocess.py']},\n",
       " 'RoleArn': 'arn:aws:iam::202646161072:role/LabRole',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:202646161072:processing-job/sagemaker-scikit-learn-2024-06-20-02-35-30-277',\n",
       " 'ProcessingJobStatus': 'Completed',\n",
       " 'ProcessingEndTime': datetime.datetime(2024, 6, 20, 2, 39, 7, tzinfo=tzlocal()),\n",
       " 'ProcessingStartTime': datetime.datetime(2024, 6, 20, 2, 36, 13, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 6, 20, 2, 40, 32, 548000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2024, 6, 20, 2, 35, 30, 712000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '85431e70-5749-460b-91fd-7b293545fd87',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '85431e70-5749-460b-91fd-7b293545fd87',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2403',\n",
       "   'date': 'Thu, 20 Jun 2024 02:47:46 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_processor.jobs[0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197a01a-d284-436c-8b8d-c42175d3f00a",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ff07c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: xgb-randsearch-20240620-07-03-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 62\u001b[0m\n\u001b[1;32m     52\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mTrainingInput(\n\u001b[1;32m     53\u001b[0m     s3_validation_data,\n\u001b[1;32m     54\u001b[0m     distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFullyReplicated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Fit the tuner\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgb-randsearch-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# train_args = xgb.fit(\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#     inputs={\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#         \"train\": TrainingInput(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# step_train_model = TrainingStep(name=\"TrainXGBModel1\", step_args=train_args)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/tuner.py:1040\u001b[0m, in \u001b[0;36mHyperparameterTuner.fit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_with_estimator_dict(inputs, job_name, include_cls_metadata, estimator_kwargs)\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/tuner.py:2345\u001b[0m, in \u001b[0;36m_TuningJob.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Placeholder docstring.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_tuning_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5179\u001b[0m, in \u001b[0;36mSession.wait_for_tuning_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   5165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_tuning_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   5166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wait for an Amazon SageMaker hyperparameter tuning job to complete.\u001b[39;00m\n\u001b[1;32m   5167\u001b[0m \n\u001b[1;32m   5168\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5177\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If the hyperparameter tuning job fails.\u001b[39;00m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5179\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43m_wait_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_tuning_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5180\u001b[0m     _check_job_status(job, desc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameterTuningJobStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:7802\u001b[0m, in \u001b[0;36m_wait_until\u001b[0;34m(callable_fn, poll)\u001b[0m\n\u001b[1;32m   7800\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   7801\u001b[0m     elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m poll\n\u001b[0;32m-> 7802\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7803\u001b[0m     result \u001b[38;5;241m=\u001b[39m callable_fn()\n\u001b[1;32m   7804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m botocore\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   7805\u001b[0m     \u001b[38;5;66;03m# For initial 5 mins we accept/pass AccessDeniedException.\u001b[39;00m\n\u001b[1;32m   7806\u001b[0m     \u001b[38;5;66;03m# The reason is to await tag propagation to avoid false AccessDenied claims for an\u001b[39;00m\n\u001b[1;32m   7807\u001b[0m     \u001b[38;5;66;03m# access policy based on resource tags, The caveat here is for true AccessDenied\u001b[39;00m\n\u001b[1;32m   7808\u001b[0m     \u001b[38;5;66;03m# cases the routine will fail after 5 mins\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "container = retrieve(\"xgboost\", region, \"1.7-1\")\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    base_job_name=BASE_JOB_TRAINING_NAME + '-xgboost',\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=S3_PATH + MODEL_PREFIX + 'xgboost',\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(objective='reg:squarederror',num_round=100)\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'eta': ContinuousParameter(0.001, 0.2),\n",
    "    'max_depth': IntegerParameter(3, 50),\n",
    "    'min_child_weight': IntegerParameter(1, 10),\n",
    "    'colsample_bytree': ContinuousParameter(0.5, 1)\n",
    "}\n",
    "\n",
    "objective_metric_name = 'validation:rmse'\n",
    "\n",
    "tuner = HyperparameterTuner(estimator=xgb,\n",
    "                            objective_metric_name=objective_metric_name,\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            objective_type='Minimize',\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=4,\n",
    "                            strategy='Random')\n",
    "\n",
    "# Specify training data location\n",
    "s3_train_data = S3_PATH + DATA_PREFIX + 'train.csv'\n",
    "s3_validation_data = S3_PATH + DATA_PREFIX + 'validation.csv'\n",
    "\n",
    "# generating the session.s3_input() format for fit() accepted by the sdk\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "tuner.fit(\n",
    "    inputs={\n",
    "        'train': train_data,\n",
    "        'validation': validation_data\n",
    "    },\n",
    "    job_name=\"xgb-randsearch-\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    ")\n",
    "\n",
    "# train_args = xgb.fit(\n",
    "#     inputs={\n",
    "#         \"train\": TrainingInput(\n",
    "#             s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "#             content_type=\"text/csv\",\n",
    "#         ),\n",
    "#         \"validation\": TrainingInput(\n",
    "#             s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"val\"].S3Output.S3Uri,\n",
    "#             content_type=\"text/csv\",\n",
    "#         )\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# step_train_model = TrainingStep(name=\"TrainXGBModel1\", step_args=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c83987a-fe01-44fc-9afb-295e00b7c385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.941825</td>\n",
       "      <td>0.117626</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>xgb-randsearch-20240620-05-16-16-005-5ab7deb7</td>\n",
       "      <td>Completed</td>\n",
       "      <td>56.492619</td>\n",
       "      <td>2024-06-20 05:37:49+00:00</td>\n",
       "      <td>2024-06-20 05:58:22+00:00</td>\n",
       "      <td>1233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.940992</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>xgb-randsearch-20240620-05-16-16-004-e652a66e</td>\n",
       "      <td>Completed</td>\n",
       "      <td>55.476940</td>\n",
       "      <td>2024-06-20 05:17:14+00:00</td>\n",
       "      <td>2024-06-20 05:37:22+00:00</td>\n",
       "      <td>1208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816160</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>xgb-randsearch-20240620-05-16-16-003-fbd05ca3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>55.984032</td>\n",
       "      <td>2024-06-20 05:17:09+00:00</td>\n",
       "      <td>2024-06-20 05:38:13+00:00</td>\n",
       "      <td>1264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.723725</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>xgb-randsearch-20240620-05-16-16-002-05678414</td>\n",
       "      <td>Completed</td>\n",
       "      <td>54.787861</td>\n",
       "      <td>2024-06-20 05:17:05+00:00</td>\n",
       "      <td>2024-06-20 05:40:48+00:00</td>\n",
       "      <td>1423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.535194</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>xgb-randsearch-20240620-05-16-16-001-be493fef</td>\n",
       "      <td>Completed</td>\n",
       "      <td>53.900372</td>\n",
       "      <td>2024-06-20 05:17:02+00:00</td>\n",
       "      <td>2024-06-20 05:35:00+00:00</td>\n",
       "      <td>1078.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colsample_bytree       eta  max_depth  min_child_weight  \\\n",
       "0          0.941825  0.117626       30.0               7.0   \n",
       "1          0.940992  0.001262       26.0              10.0   \n",
       "2          0.816160  0.036128       31.0               3.0   \n",
       "3          0.723725  0.003638       49.0               9.0   \n",
       "4          0.535194  0.016688       42.0               8.0   \n",
       "\n",
       "                                 TrainingJobName TrainingJobStatus  \\\n",
       "0  xgb-randsearch-20240620-05-16-16-005-5ab7deb7         Completed   \n",
       "1  xgb-randsearch-20240620-05-16-16-004-e652a66e         Completed   \n",
       "2  xgb-randsearch-20240620-05-16-16-003-fbd05ca3         Completed   \n",
       "3  xgb-randsearch-20240620-05-16-16-002-05678414         Completed   \n",
       "4  xgb-randsearch-20240620-05-16-16-001-be493fef         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0            56.492619 2024-06-20 05:37:49+00:00 2024-06-20 05:58:22+00:00   \n",
       "1            55.476940 2024-06-20 05:17:14+00:00 2024-06-20 05:37:22+00:00   \n",
       "2            55.984032 2024-06-20 05:17:09+00:00 2024-06-20 05:38:13+00:00   \n",
       "3            54.787861 2024-06-20 05:17:05+00:00 2024-06-20 05:40:48+00:00   \n",
       "4            53.900372 2024-06-20 05:17:02+00:00 2024-06-20 05:35:00+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                      1233.0  \n",
       "1                      1208.0  \n",
       "2                      1264.0  \n",
       "3                      1423.0  \n",
       "4                      1078.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tuner = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "df_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62c63756-21a0-4f0e-9319-dcf05b171f78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgb-randsearch-20240620-05-16-16-001-be493fef'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_name = df_tuner.sort_values('FinalObjectiveValue',ascending=True).iloc[0]['TrainingJobName']\n",
    "best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eaa0480-d670-450f-9bc5-965dcaa46949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-836402295281/GROUP6/model/xgboost/xgb-randsearch-20240619-14-39-43-001-2a4b13da/output/model.tar.gz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_name = 'xgb-randsearch-20240619-14-39-43-001-2a4b13da'\n",
    "best_xgb_path = f'{S3_PATH}{MODEL_PREFIX}xgboost/{best_xgb_name}/output/model.tar.gz'\n",
    "best_xgb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aadc1387-1f3e-4480-8ab3-c89cf5b84406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-06-30-13-31-10-621\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-06-30-13-31-11-338\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-06-30-13-31-11-338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint sagemaker-xgboost-2024-06-30-13-31-11-338: Failed. Reason: Image size 11789822572 is greater than supported size 10737418240. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mModel(\n\u001b[1;32m      9\u001b[0m     image_uri\u001b[38;5;241m=\u001b[39mxgb_image,\n\u001b[1;32m     10\u001b[0m     model_data\u001b[38;5;241m=\u001b[39mbest_xgb_path,\n\u001b[1;32m     11\u001b[0m     role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[1;32m     12\u001b[0m     sagemaker_session\u001b[38;5;241m=\u001b[39msagemaker_session\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Deploy the model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mServerlessInferenceConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/model.py:1662\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1660\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1662\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1675\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5635\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict, live_logging, vpc_config, enable_network_isolation, role)\u001b[0m\n\u001b[1;32m   5632\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m   5633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n\u001b[0;32m-> 5635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4493\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait, live_logging)\u001b[0m\n\u001b[1;32m   4490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_arn \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpointArn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   4492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4493\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5278\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll, live_logging)\u001b[0m\n\u001b[1;32m   5272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   5273\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   5274\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   5275\u001b[0m             allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   5276\u001b[0m             actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   5277\u001b[0m         )\n\u001b[0;32m-> 5278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   5279\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   5280\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   5281\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   5282\u001b[0m     )\n\u001b[1;32m   5283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint sagemaker-xgboost-2024-06-30-13-31-11-338: Failed. Reason: Image size 11789822572 is greater than supported size 10737418240. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "# Retrieve the image URI for the linear-learner algorithm\n",
    "xgb_image = retrieve(framework='xgboost', region=region, version='1.7-1')\n",
    "\n",
    "# Create a SageMaker model\n",
    "model = sagemaker.Model(\n",
    "    image_uri=xgb_image,\n",
    "    model_data=best_xgb_path,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "model.deploy(\n",
    "    serverless_inference_config=ServerlessInferenceConfig()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "88008659-e95b-4b49-bda8-a1d65191797d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a predictor\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name='sagemaker-xgboost-2024-06-21-06-26-17-576'\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "payload = test_df.iloc[:10,1:].to_csv(header=False, index=False)\n",
    "p = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2ea70547-436e-431a-9724-604db8ba9134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "pred_list = []\n",
    "while i <= len(test_df):\n",
    "    payload = test_df.iloc[i:i+1000,1:].to_csv(header=False, index=False)\n",
    "    output = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    pred = output.decode('utf-8').split('\\n')[:-1]\n",
    "    pred_list += pred\n",
    "    i += 1000\n",
    "\n",
    "xgb_predicted = np.array(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e6a8027-dd8a-4dde-8f2e-4b12b0f3c4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost test RMSE: 49.99842436026933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_df.iloc[:,0].values,predicted.astype(float))\n",
    "print(f'XGBoost test RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db15ef69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluate_xgboost.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluate_xgboost.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "label_column = 'Dep_Delay'\n",
    "\n",
    "model_tar_path = '/opt/ml/processing/model/model.tar.gz'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Your code to perform model evaluation on testing dataset, and \n",
    "    ## store the evaluation report\n",
    "    with tarfile.open(model_tar_path, 'r:gz') as tar:\n",
    "        tar.extractall(path='./model')\n",
    "    \n",
    "    xgb_model = xgboost.Booster()\n",
    "    xgb_model.load_model('./model/xgboost-model')\n",
    "    \n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    df = pd.read_csv(test_path + \"/test.csv\")\n",
    "\n",
    "    x_test = xgboost.DMatrix(df.iloc[:,1:].values)\n",
    "    y_test = df.iloc[:,0].values\n",
    "    y_pred = xgb_model.predict(x_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"\\nTest RMSE :\", score)\n",
    "\n",
    "    # Available metrics to add to model: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"rmse\": {\"value\": score, \"standard_deviation\": \"NaN\"},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5865eb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-xgboost-2024-06-20-15-23-50-390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............\u001b[34mTest RMSE : 49.99842436026933\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.processing import ScriptProcessor\n",
    "\n",
    "s3_test_data = f'{S3_PATH}{DATA_PREFIX}test.csv'\n",
    "\n",
    "xgb_eval_image = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version='1.7-1'\n",
    ")\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    role=role,\n",
    "    image_uri=xgb_eval_image,\n",
    "    command=[\"python3\"],\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "# Create a PropertyFile\n",
    "# A PropertyFile is used to be able to reference outputs from a processing step, for instance to use in a condition step.\n",
    "# For more information, visit https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# eval_args = \n",
    "evaluate_model_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=best_model_path,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=s3_test_data,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", destination=f'{S3_PATH}{GROUP_NAME}/evaluation/xgboost/'),\n",
    "    ],\n",
    "    code=\"code/evaluate_xgboost.py\",\n",
    ")\n",
    "\n",
    "# step_evaluate_model = ProcessingStep(\n",
    "#     name=\"EvaluateXgboost\",\n",
    "#     step_args=eval_args,\n",
    "#     property_files=[evaluation_report],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f3afd-a185-4d6a-b571-306c97b0cd36",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "809bebee-53f9-4679-9c60-2893a790d375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: lr-randsearch-20240620-15-39-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 71\u001b[0m\n\u001b[1;32m     54\u001b[0m train_data \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mTrainingInput(\n\u001b[1;32m     55\u001b[0m     s3_train_data,\n\u001b[1;32m     56\u001b[0m     distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFullyReplicated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mTrainingInput(\n\u001b[1;32m     63\u001b[0m     s3_validation_data,\n\u001b[1;32m     64\u001b[0m     distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFullyReplicated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 71\u001b[0m \u001b[43mtuner_lr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr-randsearch-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/tuner.py:1040\u001b[0m, in \u001b[0;36mHyperparameterTuner.fit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_with_estimator_dict(inputs, job_name, include_cls_metadata, estimator_kwargs)\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/tuner.py:2345\u001b[0m, in \u001b[0;36m_TuningJob.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Placeholder docstring.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_tuning_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5179\u001b[0m, in \u001b[0;36mSession.wait_for_tuning_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   5165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_tuning_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   5166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wait for an Amazon SageMaker hyperparameter tuning job to complete.\u001b[39;00m\n\u001b[1;32m   5167\u001b[0m \n\u001b[1;32m   5168\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5177\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If the hyperparameter tuning job fails.\u001b[39;00m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5179\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43m_wait_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_tuning_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5180\u001b[0m     _check_job_status(job, desc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameterTuningJobStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:7802\u001b[0m, in \u001b[0;36m_wait_until\u001b[0;34m(callable_fn, poll)\u001b[0m\n\u001b[1;32m   7800\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   7801\u001b[0m     elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m poll\n\u001b[0;32m-> 7802\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7803\u001b[0m     result \u001b[38;5;241m=\u001b[39m callable_fn()\n\u001b[1;32m   7804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m botocore\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   7805\u001b[0m     \u001b[38;5;66;03m# For initial 5 mins we accept/pass AccessDeniedException.\u001b[39;00m\n\u001b[1;32m   7806\u001b[0m     \u001b[38;5;66;03m# The reason is to await tag propagation to avoid false AccessDenied claims for an\u001b[39;00m\n\u001b[1;32m   7807\u001b[0m     \u001b[38;5;66;03m# access policy based on resource tags, The caveat here is for true AccessDenied\u001b[39;00m\n\u001b[1;32m   7808\u001b[0m     \u001b[38;5;66;03m# cases the routine will fail after 5 mins\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.amazon.randomcutforest import RandomCutForest\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "container = retrieve(\"linear-learner\", region, version=\"1\")\n",
    "\n",
    "# Setup the Random Forest estimator\n",
    "lr = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    input_mode='File',\n",
    "    base_job_name=BASE_JOB_TRAINING_NAME + 'linear',\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=S3_PATH + MODEL_PREFIX + 'linear',\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "lr.set_hyperparameters(\n",
    "    predictor_type=\"regressor\",\n",
    "    optimizer=\"adam\",\n",
    "    mini_batch_size=100,\n",
    "    use_lr_scheduler=True\n",
    ")\n",
    "\n",
    "# Hyperparameters can be tuned as per the specific requirements\n",
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(0.01, 0.2),\n",
    "    'wd': ContinuousParameter(0.0, 0.01)\n",
    "}\n",
    "\n",
    "objective_metric_name = 'validation:rmse'  # Adjust the metric name based on what is relevant for Random Forest in SageMaker\n",
    "\n",
    "tuner_lr = HyperparameterTuner(estimator=lr,\n",
    "                            objective_metric_name=objective_metric_name,\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            objective_type='Minimize',\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=5,\n",
    "                            strategy='Random')\n",
    "\n",
    "# Define training and validation datasets\n",
    "# Specify training data location\n",
    "s3_train_data = S3_PATH + DATA_PREFIX + 'train.csv'\n",
    "s3_validation_data = S3_PATH + DATA_PREFIX + 'validation.csv'\n",
    "\n",
    "# generating the session.s3_input() format for fit() accepted by the sdk\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "\n",
    "tuner_lr.fit(\n",
    "    inputs={\n",
    "        'train': train_data,\n",
    "        'validation': validation_data\n",
    "    },\n",
    "    job_name=\"lr-randsearch-\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f8eb058-8921-401e-9cbe-358993620195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>wd</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041387</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>lr-randsearch-20240620-13-40-45-005-03b1ccb1</td>\n",
       "      <td>Completed</td>\n",
       "      <td>54.109787</td>\n",
       "      <td>2024-06-20 13:41:55+00:00</td>\n",
       "      <td>2024-06-20 13:53:37+00:00</td>\n",
       "      <td>702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039622</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>lr-randsearch-20240620-13-40-45-004-4a059713</td>\n",
       "      <td>Completed</td>\n",
       "      <td>54.105003</td>\n",
       "      <td>2024-06-20 13:41:55+00:00</td>\n",
       "      <td>2024-06-20 13:53:36+00:00</td>\n",
       "      <td>701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195047</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>lr-randsearch-20240620-13-40-45-003-6d7fd290</td>\n",
       "      <td>Completed</td>\n",
       "      <td>54.368877</td>\n",
       "      <td>2024-06-20 13:41:39+00:00</td>\n",
       "      <td>2024-06-20 13:55:36+00:00</td>\n",
       "      <td>837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>lr-randsearch-20240620-13-40-45-002-81033a3e</td>\n",
       "      <td>Completed</td>\n",
       "      <td>54.115536</td>\n",
       "      <td>2024-06-20 13:41:48+00:00</td>\n",
       "      <td>2024-06-20 13:52:23+00:00</td>\n",
       "      <td>635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118939</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>lr-randsearch-20240620-13-40-45-001-d346b7c3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>54.113075</td>\n",
       "      <td>2024-06-20 13:41:59+00:00</td>\n",
       "      <td>2024-06-20 13:54:30+00:00</td>\n",
       "      <td>751.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate        wd                               TrainingJobName  \\\n",
       "0       0.041387  0.007256  lr-randsearch-20240620-13-40-45-005-03b1ccb1   \n",
       "1       0.039622  0.007937  lr-randsearch-20240620-13-40-45-004-4a059713   \n",
       "2       0.195047  0.000752  lr-randsearch-20240620-13-40-45-003-6d7fd290   \n",
       "3       0.015839  0.008427  lr-randsearch-20240620-13-40-45-002-81033a3e   \n",
       "4       0.118939  0.006393  lr-randsearch-20240620-13-40-45-001-d346b7c3   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0         Completed            54.109787 2024-06-20 13:41:55+00:00   \n",
       "1         Completed            54.105003 2024-06-20 13:41:55+00:00   \n",
       "2         Completed            54.368877 2024-06-20 13:41:39+00:00   \n",
       "3         Completed            54.115536 2024-06-20 13:41:48+00:00   \n",
       "4         Completed            54.113075 2024-06-20 13:41:59+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0 2024-06-20 13:53:37+00:00                       702.0  \n",
       "1 2024-06-20 13:53:36+00:00                       701.0  \n",
       "2 2024-06-20 13:55:36+00:00                       837.0  \n",
       "3 2024-06-20 13:52:23+00:00                       635.0  \n",
       "4 2024-06-20 13:54:30+00:00                       751.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tuner_lr = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    tuner_lr.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "df_tuner_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3666bbbb-8f9c-45b0-8fa7-140202d227e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-836402295281/GROUP6/model/linear/lr-randsearch-20240620-13-40-45-004-4a059713/output/model.tar.gz'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_linear_name = 'lr-randsearch-20240620-13-40-45-004-4a059713'\n",
    "best_linear_path = f'{S3_PATH}{MODEL_PREFIX}linear/{best_linear_name}/output/model.tar.gz'\n",
    "best_linear_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f2778-8993-4083-acb3-4fe50f5e288d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating model with name: linear-learner-2024-06-21-07-03-28-228\n",
      "INFO:sagemaker:Creating endpoint-config with name linear-learner-2024-06-21-07-03-28-931\n",
      "INFO:sagemaker:Creating endpoint with name linear-learner-2024-06-21-07-03-28-931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------"
     ]
    }
   ],
   "source": [
    "# Retrieve the image URI for the linear-learner algorithm\n",
    "image_uri = retrieve(framework='linear-learner', region=region, version='1')\n",
    "\n",
    "# Create a SageMaker model\n",
    "model = sagemaker.Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=best_linear_path,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0c021941-264c-4b22-be4f-14fc60773315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'linear-learner-2024-06-21-07-03-28-931'\n",
    "\n",
    "# Initialize a predictor\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8064164e-fc0b-47d7-9273-d94bd101735e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "pred_list = []\n",
    "while i <= len(test_df):\n",
    "    payload = test_df.iloc[i:i+1000,1:].to_csv(header=False, index=False)\n",
    "    output = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    output = json.loads(output.decode('utf-8'))\n",
    "    pred = [out['score'] for out in output['predictions']]\n",
    "    pred_list += pred\n",
    "    i += 1000\n",
    "\n",
    "predicted_linear = np.array(pred_list).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c72f5c47-b649-4fcd-bd12-b0cb3a791569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear learner test RMSE: 50.139236350073425\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df.iloc[:,0].values,predicted)\n",
    "print(f'Linear learner test RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729aded-9e10-4fc3-a53b-b62ea6cbce88",
   "metadata": {},
   "source": [
    "### Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1958d9-6fc9-4a5e-a6fd-25ef00afec10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: fm-randsearch-20240621-03-28-46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from time import gmtime, strftime\n",
    "\n",
    "fm_container = retrieve('factorization-machines',region)\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(\n",
    "    fm_container,\n",
    "    role,\n",
    "    base_job_name=BASE_JOB_TRAINING_NAME + '-fm',\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=S3_PATH + MODEL_PREFIX + 'fm',\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=813,\n",
    "                       num_factors=64,\n",
    "                       predictor_type='regressor',\n",
    "                       mini_batch_size=1000)\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'factors_wd': ContinuousParameter(1e-8, 1e-4),\n",
    "    'linear_wd': ContinuousParameter(1e-8, 1e-4),\n",
    "    'bias_wd': ContinuousParameter(1e-8, 1e-4),\n",
    "    'epochs': IntegerParameter(10, 100)\n",
    "}\n",
    "\n",
    "objective_metric_name = 'validation:rmse'\n",
    "\n",
    "fm_tuner = HyperparameterTuner(estimator=fm,\n",
    "                            objective_metric_name='test:rmse',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            objective_type='Minimize',\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=5,\n",
    "                            strategy='Random')\n",
    "\n",
    "# Specify training data location\n",
    "s3_train_data = S3_PATH + DATA_PREFIX + 'train.csv'\n",
    "s3_validation_data = S3_PATH + DATA_PREFIX + 'validation.csv'\n",
    "\n",
    "# generating the session.s3_input() format for fit() accepted by the sdk\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "fm_tuner.fit(\n",
    "    inputs={\n",
    "        'train': train_data,\n",
    "        'test': validation_data\n",
    "    },\n",
    "    job_name=\"fm-randsearch-\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7263fa9a-0042-415e-acdd-9fbb6927f8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias_wd</th>\n",
       "      <th>epochs</th>\n",
       "      <th>factors_wd</th>\n",
       "      <th>linear_wd</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.768333e-07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.933619e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>fm-randsearch-20240621-03-28-46-005-29bc72cf</td>\n",
       "      <td>Completed</td>\n",
       "      <td>149.103622</td>\n",
       "      <td>2024-06-21 03:29:41+00:00</td>\n",
       "      <td>2024-06-21 03:39:11+00:00</td>\n",
       "      <td>570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.242554e-05</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.475626e-08</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>fm-randsearch-20240621-03-28-46-004-1f596440</td>\n",
       "      <td>Completed</td>\n",
       "      <td>102.370323</td>\n",
       "      <td>2024-06-21 03:29:41+00:00</td>\n",
       "      <td>2024-06-21 03:40:16+00:00</td>\n",
       "      <td>635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.816215e-06</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.000964e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>fm-randsearch-20240621-03-28-46-003-5c321590</td>\n",
       "      <td>Completed</td>\n",
       "      <td>94.614632</td>\n",
       "      <td>2024-06-21 03:29:41+00:00</td>\n",
       "      <td>2024-06-21 03:42:52+00:00</td>\n",
       "      <td>791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.218829e-08</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.058090e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>fm-randsearch-20240621-03-28-46-002-148f5a50</td>\n",
       "      <td>Completed</td>\n",
       "      <td>80.167862</td>\n",
       "      <td>2024-06-21 03:29:34+00:00</td>\n",
       "      <td>2024-06-21 03:45:11+00:00</td>\n",
       "      <td>937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.630834e-07</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.659995e-08</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>fm-randsearch-20240621-03-28-46-001-7acd1054</td>\n",
       "      <td>Completed</td>\n",
       "      <td>78.112427</td>\n",
       "      <td>2024-06-21 03:29:35+00:00</td>\n",
       "      <td>2024-06-21 03:45:12+00:00</td>\n",
       "      <td>937.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bias_wd  epochs    factors_wd  linear_wd  \\\n",
       "0  9.768333e-07    21.0  4.933619e-05   0.000002   \n",
       "1  5.242554e-05    29.0  1.475626e-08   0.000050   \n",
       "2  3.816215e-06    41.0  1.000964e-06   0.000001   \n",
       "3  3.218829e-08    48.0  5.058090e-05   0.000006   \n",
       "4  2.630834e-07    50.0  1.659995e-08   0.000019   \n",
       "\n",
       "                                TrainingJobName TrainingJobStatus  \\\n",
       "0  fm-randsearch-20240621-03-28-46-005-29bc72cf         Completed   \n",
       "1  fm-randsearch-20240621-03-28-46-004-1f596440         Completed   \n",
       "2  fm-randsearch-20240621-03-28-46-003-5c321590         Completed   \n",
       "3  fm-randsearch-20240621-03-28-46-002-148f5a50         Completed   \n",
       "4  fm-randsearch-20240621-03-28-46-001-7acd1054         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0           149.103622 2024-06-21 03:29:41+00:00 2024-06-21 03:39:11+00:00   \n",
       "1           102.370323 2024-06-21 03:29:41+00:00 2024-06-21 03:40:16+00:00   \n",
       "2            94.614632 2024-06-21 03:29:41+00:00 2024-06-21 03:42:52+00:00   \n",
       "3            80.167862 2024-06-21 03:29:34+00:00 2024-06-21 03:45:11+00:00   \n",
       "4            78.112427 2024-06-21 03:29:35+00:00 2024-06-21 03:45:12+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                       570.0  \n",
       "1                       635.0  \n",
       "2                       791.0  \n",
       "3                       937.0  \n",
       "4                       937.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tuner_fm = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    fm_tuner.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "df_tuner_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5edc40dd-de89-40ad-aa43-761c831544e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-836402295281/GROUP6/model/fm/fm-randsearch-20240621-03-28-46-001-7acd1054/output/model.tar.gz'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fm_name = df_tuner_fm.sort_values('FinalObjectiveValue',ascending=True).iloc[0]['TrainingJobName']\n",
    "best_fm_path = f'{S3_PATH}{MODEL_PREFIX}fm/{best_fm_name}/output/model.tar.gz'\n",
    "best_fm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2255fda7-54f8-4a28-ab5b-7f392cb6082c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating model with name: factorization-machines-2024-06-21-07-39-47-084\n",
      "INFO:sagemaker:Creating endpoint-config with name factorization-machines-2024-06-21-07-39-47-771\n",
      "INFO:sagemaker:Creating endpoint with name factorization-machines-2024-06-21-07-39-47-771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# Retrieve the image URI for the linear-learner algorithm\n",
    "image_uri = retrieve(framework='factorization-machines', region=region, version='1')\n",
    "\n",
    "# Create a SageMaker model\n",
    "model = sagemaker.Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=best_fm_path,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "89f73267-2caa-4180-b0e4-a67d7b0b5cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'factorization-machines-2024-06-21-07-39-47-771'\n",
    "\n",
    "# Initialize a predictor\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "class FMSerializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "        js = {\"instances\": []}\n",
    "        for row in data:\n",
    "            js[\"instances\"].append({\"features\": row.tolist()})\n",
    "        return json.dumps(js)\n",
    "\n",
    "predictor.serializer = FMSerializer()\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c3dde72a-4330-4490-8383-74af233d8822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "pred_list = []\n",
    "while i <= len(test_df):\n",
    "    payload = test_df.iloc[i:i+1000,1:].values\n",
    "    output = predictor.predict(payload, initial_args={\"ContentType\": \"application/json\"})\n",
    "    pred = [out['score'] for out in output['predictions']]\n",
    "    pred_list += pred\n",
    "    i += 1000\n",
    "\n",
    "predicted_fm = np.array(pred_list).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b101335f-a64c-4338-8349-b1331f82313e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorization Machines test RMSE: 73.72534226067884\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df.iloc[:,0].values,predicted)\n",
    "print(f'Factorization Machines test RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ff57b-2647-4c91-a559-688e6dbf9bf7",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a50565ff-d138-4912-8f16-b3c3b61f4949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: lgbm-rand-20240621-04-14-39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "from sagemaker import hyperparameters\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from time import gmtime, strftime\n",
    "\n",
    "train_model_id, train_model_version, train_scope = \"lightgbm-regression-model\", \"*\", \"training\"\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")\n",
    "\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "\n",
    "lgbm = sagemaker.estimator.Estimator(\n",
    "    role=role,\n",
    "    base_job_name=BASE_JOB_TRAINING_NAME + '-lgbm',\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=S3_PATH + MODEL_PREFIX + 'lgbm',\n",
    ")\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=813,\n",
    "                       num_factors=64,\n",
    "                       predictor_type='regressor',\n",
    "                       mini_batch_size=1000)\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(1e-4, 1, scaling_type=\"Logarithmic\"),\n",
    "    \"num_boost_round\": IntegerParameter(2, 30),\n",
    "    \"early_stopping_rounds\": IntegerParameter(2, 30),\n",
    "    \"num_leaves\": IntegerParameter(10, 50),\n",
    "    \"feature_fraction\": ContinuousParameter(0, 1),\n",
    "    \"bagging_fraction\": ContinuousParameter(0, 1),\n",
    "    \"bagging_freq\": IntegerParameter(1, 10),\n",
    "    \"max_depth\": IntegerParameter(5, 30),\n",
    "    \"min_data_in_leaf\": IntegerParameter(5, 50),\n",
    "}\n",
    "\n",
    "# objective_metric_name = 'validation:rmse'\n",
    "\n",
    "# lgbm_tuner = HyperparameterTuner(\n",
    "#     lgbm,\n",
    "#     \"rmse\",\n",
    "#     hyperparameter_ranges,\n",
    "#     [{\"Name\": \"rmse\", \"Regex\": \"rmse: ([0-9\\\\.]+)\"}],\n",
    "#     max_jobs=5,\n",
    "#     max_parallel_jobs=5,\n",
    "#     objective_type=\"Minimize\",\n",
    "#     strategy='Random'\n",
    "# )\n",
    "\n",
    "# lgbm_tuner.fit({\"training\": training_dataset_s3_path}, logs=True)\n",
    "\n",
    "lgbm_tuner = HyperparameterTuner(estimator=lgbm,\n",
    "                            objective_metric_name='rmse',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            metric_definitions=[{\"Name\": \"rmse\", \"Regex\": \"rmse: ([0-9\\\\.]+)\"}],\n",
    "                            objective_type='Minimize',\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=5,\n",
    "                            strategy='Random')\n",
    "\n",
    "# Specify training data location\n",
    "s3_train_data = S3_PATH + DATA_PREFIX + 'train.csv'\n",
    "s3_validation_data = S3_PATH + DATA_PREFIX + 'validation.csv'\n",
    "\n",
    "# generating the session.s3_input() format for fit() accepted by the sdk\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "lgbm_tuner.fit(\n",
    "    inputs={\n",
    "        'train': train_data,\n",
    "        'validation': validation_data\n",
    "    },\n",
    "    job_name=\"lgbm-rand-\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c7f7ef-92d6-4529-b29c-2fc4ac06e5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>early_stopping_rounds</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>num_boost_round</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571666</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.161938</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>lgbm-rand-20240621-04-14-39-005-af474496</td>\n",
       "      <td>Completed</td>\n",
       "      <td>53.001099</td>\n",
       "      <td>2024-06-21 04:15:34+00:00</td>\n",
       "      <td>2024-06-21 04:17:18+00:00</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560695</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.295746</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>lgbm-rand-20240621-04-14-39-004-543173dd</td>\n",
       "      <td>Completed</td>\n",
       "      <td>53.100601</td>\n",
       "      <td>2024-06-21 04:15:34+00:00</td>\n",
       "      <td>2024-06-21 04:17:12+00:00</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.258755</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.381989</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>lgbm-rand-20240621-04-14-39-003-fccd40f6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>53.098000</td>\n",
       "      <td>2024-06-21 04:15:32+00:00</td>\n",
       "      <td>2024-06-21 04:17:15+00:00</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246200</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.923566</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>lgbm-rand-20240621-04-14-39-002-3f679207</td>\n",
       "      <td>Completed</td>\n",
       "      <td>53.098701</td>\n",
       "      <td>2024-06-21 04:15:30+00:00</td>\n",
       "      <td>2024-06-21 04:17:09+00:00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019957</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.464040</td>\n",
       "      <td>0.379247</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>lgbm-rand-20240621-04-14-39-001-2f125bcc</td>\n",
       "      <td>Completed</td>\n",
       "      <td>53.174000</td>\n",
       "      <td>2024-06-21 04:15:27+00:00</td>\n",
       "      <td>2024-06-21 04:17:11+00:00</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bagging_fraction  bagging_freq  early_stopping_rounds  feature_fraction  \\\n",
       "0          0.571666           5.0                    8.0          0.161938   \n",
       "1          0.560695           9.0                   10.0          0.295746   \n",
       "2          0.258755           6.0                   14.0          0.381989   \n",
       "3          0.246200           7.0                   25.0          0.923566   \n",
       "4          0.019957           2.0                   11.0          0.464040   \n",
       "\n",
       "   learning_rate  max_depth  min_data_in_leaf  num_boost_round  num_leaves  \\\n",
       "0       0.007978       29.0              30.0             19.0        45.0   \n",
       "1       0.000187       28.0              11.0              8.0        17.0   \n",
       "2       0.000261       15.0              17.0             13.0        37.0   \n",
       "3       0.000251       18.0              27.0             10.0        21.0   \n",
       "4       0.379247       22.0               6.0             16.0        34.0   \n",
       "\n",
       "                            TrainingJobName TrainingJobStatus  \\\n",
       "0  lgbm-rand-20240621-04-14-39-005-af474496         Completed   \n",
       "1  lgbm-rand-20240621-04-14-39-004-543173dd         Completed   \n",
       "2  lgbm-rand-20240621-04-14-39-003-fccd40f6         Completed   \n",
       "3  lgbm-rand-20240621-04-14-39-002-3f679207         Completed   \n",
       "4  lgbm-rand-20240621-04-14-39-001-2f125bcc         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0            53.001099 2024-06-21 04:15:34+00:00 2024-06-21 04:17:18+00:00   \n",
       "1            53.100601 2024-06-21 04:15:34+00:00 2024-06-21 04:17:12+00:00   \n",
       "2            53.098000 2024-06-21 04:15:32+00:00 2024-06-21 04:17:15+00:00   \n",
       "3            53.098701 2024-06-21 04:15:30+00:00 2024-06-21 04:17:09+00:00   \n",
       "4            53.174000 2024-06-21 04:15:27+00:00 2024-06-21 04:17:11+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                       104.0  \n",
       "1                        98.0  \n",
       "2                       103.0  \n",
       "3                        99.0  \n",
       "4                       104.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tuner_lgbm = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    lgbm_tuner.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "df_tuner_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b03a6ee-7f5d-4cda-bfea-735dab02257c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-836402295281/GROUP6/model/lgbm/lgbm-rand-20240621-04-14-39-005-af474496/output/model.tar.gz'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgbm_name = df_tuner_lgbm.sort_values('FinalObjectiveValue',ascending=True).iloc[0]['TrainingJobName']\n",
    "best_lgbm_path = f'{S3_PATH}{MODEL_PREFIX}lgbm/{best_lgbm_name}/output/model.tar.gz'\n",
    "best_lgbm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1134b01-4cc0-4901-9f76-7f4f3afefb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-836402295281/GROUP6/model/lgbm/lgbm-rand-20240621-04-14-39-005-af474496/output/model.tar.gz), script artifact (s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/lightgbm/inference/regression/v1.2.1/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-836402295281/pytorch-inference-2024-06-21-08-26-13-434/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: sagemaker-jumpstart-2024-06-21-08-26-15-013\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-jumpstart-2024-06-21-08-26-15-754\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-jumpstart-2024-06-21-08-26-15-754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "model_id, model_version, scope = \"lightgbm-regression-model\", \"*\", \"inference\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=scope,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type='ml.m5.xlarge',\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=scope\n",
    ")\n",
    "\n",
    "# Create a SageMaker model\n",
    "model = sagemaker.Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    model_data=best_lgbm_path,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e602f9cb-4457-41c2-abcb-a1c14a86868d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'sagemaker-jumpstart-2024-06-21-08-26-15-754'\n",
    "\n",
    "# Initialize a predictor\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fd2e5e03-cce1-4972-9426-e9d28c117496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "pred_list = []\n",
    "while i <= len(test_df):\n",
    "    payload = test_df.iloc[i:i+1000,1:].to_csv(header=False,index=False)\n",
    "    output = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    output = json.loads(output.decode('utf-8'))\n",
    "    pred = [out for out in output['prediction']]\n",
    "    pred_list += pred\n",
    "    i += 1000\n",
    "\n",
    "predicted_lgbm = np.array(pred_list).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3641b2db-ddab-4fea-89e0-48ac585b6075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average = sum([predicted_lgbm,predicted_linear,predicted_fm,xgb_predicted.astype(float)]) / len(xgb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fa1613d5-ed2c-4ba2-8ab9-342260df64e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.47925758, 16.74202919,  1.46071875, ..., 11.01685238,\n",
       "       -1.37145734,  6.0683918 ])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predicted.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "76d1d1f0-6247-45bf-ac1d-5bacf41e69b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM test RMSE: 52.26957501090619\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df.iloc[:,0].values,average)\n",
    "print(f'LightGBM test RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d185ffcf-dda5-44f3-85b0-4f9049ef7b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1472bb9e-81e8-4b33-abdf-4a83b9e095e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>803</th>\n",
       "      <th>804</th>\n",
       "      <th>805</th>\n",
       "      <th>806</th>\n",
       "      <th>807</th>\n",
       "      <th>808</th>\n",
       "      <th>809</th>\n",
       "      <th>810</th>\n",
       "      <th>811</th>\n",
       "      <th>812</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.002819</td>\n",
       "      <td>0.695288</td>\n",
       "      <td>1.208326</td>\n",
       "      <td>1.498681</td>\n",
       "      <td>1.006576</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>-0.317248</td>\n",
       "      <td>1.817442</td>\n",
       "      <td>-0.580364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614921</td>\n",
       "      <td>-0.117039</td>\n",
       "      <td>-0.419113</td>\n",
       "      <td>-0.266520</td>\n",
       "      <td>-0.337168</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>-0.550507</td>\n",
       "      <td>-0.044904</td>\n",
       "      <td>0.905086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450429</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.684050</td>\n",
       "      <td>0.278295</td>\n",
       "      <td>0.801424</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>0.346643</td>\n",
       "      <td>-1.002682</td>\n",
       "      <td>-1.315103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356379</td>\n",
       "      <td>0.492032</td>\n",
       "      <td>0.170697</td>\n",
       "      <td>0.223814</td>\n",
       "      <td>0.062878</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>-1.402800</td>\n",
       "      <td>-1.020418</td>\n",
       "      <td>-0.404665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935445</td>\n",
       "      <td>0.610784</td>\n",
       "      <td>-1.970095</td>\n",
       "      <td>-1.835588</td>\n",
       "      <td>-1.937352</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>0.535045</td>\n",
       "      <td>-0.381900</td>\n",
       "      <td>3.348892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171078</td>\n",
       "      <td>-1.464266</td>\n",
       "      <td>-0.572027</td>\n",
       "      <td>-0.321001</td>\n",
       "      <td>-0.737214</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>0.866990</td>\n",
       "      <td>3.857154</td>\n",
       "      <td>-0.181049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188101</td>\n",
       "      <td>-1.456071</td>\n",
       "      <td>-0.648483</td>\n",
       "      <td>-0.440861</td>\n",
       "      <td>-0.850048</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>-1.483543</td>\n",
       "      <td>-1.321941</td>\n",
       "      <td>0.553690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440750</td>\n",
       "      <td>-1.253349</td>\n",
       "      <td>0.356378</td>\n",
       "      <td>0.648770</td>\n",
       "      <td>0.114166</td>\n",
       "      <td>-0.245758</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>0.436358</td>\n",
       "      <td>0.593615</td>\n",
       "      <td>-0.564391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.623049</td>\n",
       "      <td>-0.107179</td>\n",
       "      <td>-1.183681</td>\n",
       "      <td>-0.985676</td>\n",
       "      <td>-1.188548</td>\n",
       "      <td>1.457841</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>1.494995</td>\n",
       "      <td>1.498182</td>\n",
       "      <td>1.927332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171078</td>\n",
       "      <td>-1.464266</td>\n",
       "      <td>-0.451880</td>\n",
       "      <td>-0.201142</td>\n",
       "      <td>-0.562835</td>\n",
       "      <td>-0.310289</td>\n",
       "      <td>-0.103059</td>\n",
       "      <td>0.804190</td>\n",
       "      <td>3.094479</td>\n",
       "      <td>-0.037296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       803       804  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ... -2.002819  0.695288   \n",
       "1  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.614921 -0.117039   \n",
       "2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.450429  0.006493   \n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.356379  0.492032   \n",
       "4  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.935445  0.610784   \n",
       "5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.171078 -1.464266   \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.188101 -1.456071   \n",
       "7  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.440750 -1.253349   \n",
       "8  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.623049 -0.107179   \n",
       "9  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.171078 -1.464266   \n",
       "\n",
       "        805       806       807       808       809       810       811  \\\n",
       "0  1.208326  1.498681  1.006576 -0.310289 -0.103059 -0.317248  1.817442   \n",
       "1 -0.419113 -0.266520 -0.337168 -0.310289 -0.103059 -0.550507 -0.044904   \n",
       "2  0.684050  0.278295  0.801424 -0.310289 -0.103059  0.346643 -1.002682   \n",
       "3  0.170697  0.223814  0.062878 -0.310289 -0.103059 -1.402800 -1.020418   \n",
       "4 -1.970095 -1.835588 -1.937352 -0.310289 -0.103059  0.535045 -0.381900   \n",
       "5 -0.572027 -0.321001 -0.737214 -0.310289 -0.103059  0.866990  3.857154   \n",
       "6 -0.648483 -0.440861 -0.850048 -0.310289 -0.103059 -1.483543 -1.321941   \n",
       "7  0.356378  0.648770  0.114166 -0.245758 -0.103059  0.436358  0.593615   \n",
       "8 -1.183681 -0.985676 -1.188548  1.457841 -0.103059  1.494995  1.498182   \n",
       "9 -0.451880 -0.201142 -0.562835 -0.310289 -0.103059  0.804190  3.094479   \n",
       "\n",
       "        812  \n",
       "0 -0.580364  \n",
       "1  0.905086  \n",
       "2 -1.315103  \n",
       "3 -0.404665  \n",
       "4  3.348892  \n",
       "5 -0.181049  \n",
       "6  0.553690  \n",
       "7 -0.564391  \n",
       "8  1.927332  \n",
       "9 -0.037296  \n",
       "\n",
       "[10 rows x 813 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "pd.read_csv(StringIO(test_df.iloc[:10,1:].to_csv(header=False,index=False)),header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f2e717fc-8ce3-4fba-bbd7-5685b9f7789a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName='sagemaker-jumpstart-2024-06-21-08-26-15-754',\n",
    "    ContentType='text/csv',\n",
    "    Body=test_df.iloc[:10,1:].to_csv(header=False,index=False)\n",
    ")['Body'].read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cdabdd15-a521-45e0-acf1-a8459bedc487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"prediction\": [11.986738938680132, 11.420523108240525, 12.404603853311844, 11.471671713807924, 11.575639670241783, 12.006904046860821, 11.832086977913049, 11.582282082322754, 11.805968793416355, 11.784793945532899]}'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "69f06890-6868-4eaa-b2ff-14ca8cab9bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/lambda_helper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/lambda_helper.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize boto3 client for SageMaker runtime\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Endpoint names of your four models\n",
    "xgboost = 'sagemaker-xgboost-2024-06-21-06-26-17-576'\n",
    "linear = 'linear-learner-2024-06-21-07-03-28-931'\n",
    "factor = 'factorization-machines-2024-06-21-07-39-47-771'\n",
    "lgbm = 'sagemaker-jumpstart-2024-06-21-08-26-15-754'\n",
    "\n",
    "def serialize(self, data):\n",
    "        js = {\"instances\": []}\n",
    "        for row in data:\n",
    "            js[\"instances\"].append({\"features\": row.tolist()})\n",
    "        return json.dumps(js)\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    features = event['features']\n",
    "    \n",
    "    responses = []\n",
    "    \n",
    "    response_xgb = runtime.invoke_endpoint(\n",
    "        EndpointName=xgboost,\n",
    "        ContentType='text/csv',\n",
    "        Body=features\n",
    "    )\n",
    "    result_xgb = response_xgb['Body'].read().decode().split('\\n')[:-1]\n",
    "    responses.append(np.array(result_xgb).astype(float))\n",
    "    \n",
    "    response_linear = runtime.invoke_endpoint(\n",
    "        EndpointName=linear,\n",
    "        ContentType='text/csv',\n",
    "        Body=features\n",
    "    )\n",
    "    response_linear = json.loads(response_linear['Body'].read().decode())\n",
    "    result_linear = [out['score'] for out in response_linear['predictions']]\n",
    "    responses.append(np.array(result_linear).astype(float))\n",
    "    \n",
    "    df = pd.read_csv(StrintIO(features),header=None)\n",
    "    response_fm = runtime.invoke_endpoint(\n",
    "        EndpointName=factor,\n",
    "        ContentType='application/json',\n",
    "        Body=serialize(df)\n",
    "    )\n",
    "    response_fm = json.loads(response_fm['Body'].read().decode())\n",
    "    result_fm = [out['score'] for out in response_fm['predictions']]\n",
    "    responses.append(np.array(result_fm).astype(float))\n",
    "    \n",
    "    response_lgbm = runtime.invoke_endpoint(\n",
    "        EndpointName=lgbm,\n",
    "        ContentType='text/csv',\n",
    "        Body=features\n",
    "    )\n",
    "    response_lgbm = json.loads(response_lgbm['Body'].read().decode())\n",
    "    result_lgbm = [out for out in response_lgbm['prediction']]\n",
    "    responses.append(np.array(result_lgbm).astype(float))\n",
    "    \n",
    "    # Aggregate or process responses as needed\n",
    "    # For example, you can average the predictions if they are numerical\n",
    "    aggregated_result = aggregate_responses(responses)\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(aggregated_result.tolist())\n",
    "    }\n",
    "\n",
    "def aggregate_responses(responses):\n",
    "    # Example aggregation: average predictions\n",
    "    aggregated = sum(responses) / len(responses)\n",
    "    return aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "df2d4aec-7963-436f-8399-14f290d0757e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: zip: command not found\n"
     ]
    }
   ],
   "source": [
    "!zip code/lambda.zip code/lambda_helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "74b71ec6-e585-4951-ab9c-d14715894415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nInvalid type for parameter Code, value: code/lambda_helper.py, type: <class 'str'>, valid types: <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_helper.lambda_handler\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Read the deployment package\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# with open('lambda_function.zip', 'rb') as f:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     zipped_code = f.read()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create the Lambda function\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlambda_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFunctionName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRuntime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Replace with your Lambda role ARN\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHandler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcode/lambda_helper.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 5 minutes\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMemorySize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated Lambda function with ARN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunctionArn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:974\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m properties:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# Pass arbitrary endpoint info with the Request\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# for use during construction.\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     request_context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendpoint_properties\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m properties\n\u001b[0;32m--> 974\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_request_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m resolve_checksum_context(request_dict, operation_model, api_params)\n\u001b[1;32m    983\u001b[0m service_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1048\u001b[0m, in \u001b[0;36mBaseClient._convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, endpoint_url, context, headers, set_user_agent_header)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_request_dict\u001b[39m(\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1041\u001b[0m     api_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     set_user_agent_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1047\u001b[0m ):\n\u001b[0;32m-> 1048\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_to_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39minject_host_prefix:\n\u001b[1;32m   1052\u001b[0m         request_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/validate.py:381\u001b[0m, in \u001b[0;36mParamValidationDecorator.serialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    377\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_validator\u001b[38;5;241m.\u001b[39mvalidate(\n\u001b[1;32m    378\u001b[0m         parameters, operation_model\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report\u001b[38;5;241m.\u001b[39mhas_errors():\n\u001b[0;32m--> 381\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParamValidationError(report\u001b[38;5;241m=\u001b[39mreport\u001b[38;5;241m.\u001b[39mgenerate_report())\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serializer\u001b[38;5;241m.\u001b[39mserialize_to_request(\n\u001b[1;32m    383\u001b[0m     parameters, operation_model\n\u001b[1;32m    384\u001b[0m )\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nInvalid type for parameter Code, value: code/lambda_helper.py, type: <class 'str'>, valid types: <class 'dict'>"
     ]
    }
   ],
   "source": [
    "# Initialize clients\n",
    "iam_client = boto3.client('iam')\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "# Role and Lambda function settings\n",
    "role_name = 'LambdaSageMakerInvokeRole'\n",
    "function_name = 'MLE-Ensemble'\n",
    "runtime = 'python3.8'\n",
    "handler = 'lambda_helper.lambda_handler'\n",
    "\n",
    "# Read the deployment package\n",
    "# with open('lambda_function.zip', 'rb') as f:\n",
    "#     zipped_code = f.read()\n",
    "\n",
    "# Create the Lambda function\n",
    "response = lambda_client.create_function(\n",
    "    FunctionName=function_name,\n",
    "    Runtime=runtime,\n",
    "    Role=role,  # Replace with your Lambda role ARN\n",
    "    Handler=handler,\n",
    "    Code='code/lambda_helper.py',\n",
    "    Timeout=300,  # 5 minutes\n",
    "    MemorySize=128\n",
    ")\n",
    "\n",
    "print(f\"Created Lambda function with ARN: {response['FunctionArn']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00ca4f-dd70-4be1-8db1-b7ba2dbfad1b",
   "metadata": {},
   "source": [
    "### New Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfb47b5d-4047-459b-8075-2c1e95e27bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/train_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/train_inference.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Training Started\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ[\"SM_CHANNEL_VALIDATION\"])\n",
    "    parser.add_argument(\"--num_round\", type=int, default=6)\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=5)\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--objective\", type=str, default=\"reg:squarederror\")\n",
    "    parser.add_argument(\"--alpha\", type=float, default=1.0)\n",
    "    args = parser.parse_args()\n",
    "    print(\"Got Args: {}\".format(args))\n",
    "\n",
    "    # Load training and validation sets\n",
    "    train_path = os.path.join(args.train, 'train.csv')\n",
    "    train_df = pd.read_csv(train_path, header=None)\n",
    "    \n",
    "    validation_path = os.path.join(args.validation, 'validation.csv')\n",
    "    validation_df = pd.read_csv(validation_path, header=None)\n",
    "    \n",
    "    # First column is label\n",
    "    X_train = train_df.iloc[:, 1:].values\n",
    "    y_train = train_df.iloc[:, 0].values\n",
    "    \n",
    "    X_validation = validation_df.iloc[:, 1:].values\n",
    "    y_validation = validation_df.iloc[:, 0].values\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Define and Train catboost\n",
    "    \"\"\"    \n",
    "    catboost_hyperparameters = {\n",
    "        \"max_depth\": args.max_depth,\n",
    "        \"eta\": args.eta,\n",
    "    }\n",
    "\n",
    "    cat = CatBoostRegressor(**catboost_hyperparameters)\n",
    "    cat.fit(X_train,y_train,logging_level='Silent')\n",
    "\n",
    "    model_catboost = os.path.join(args.model_dir, 'catboost.dump')\n",
    "    cat.save_model(model_catboost)\n",
    "    print('Finished training catboost')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Train the XGBoost model\n",
    "    \"\"\"\n",
    "    xgb_hyperparameters = {\n",
    "        \"max_depth\": args.max_depth,\n",
    "        \"eta\": args.eta,\n",
    "        \"objective\": args.objective,\n",
    "        \"num_boost_round\": args.num_round,\n",
    "    }\n",
    "\n",
    "    dtrain = xgboost.DMatrix(data=X_train,label=y_train)\n",
    "    xgb = xgboost.train(\n",
    "        params=xgb_hyperparameters,\n",
    "        dtrain=dtrain\n",
    "    )    \n",
    "\n",
    "    model_xgb = os.path.join(args.model_dir,\"xgboost-model\")\n",
    "    pickle.dump(xgb, open(model_xgb, \"wb\"))\n",
    "    print('Finished training xgboost')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Train the elastic net model\n",
    "    \"\"\"\n",
    "    en_hyperparameters = {\n",
    "        'alpha': args.alpha\n",
    "    }\n",
    "    \n",
    "    en = ElasticNet(**en_hyperparameters)\n",
    "    en.fit(X_train,y_train)\n",
    "    \n",
    "    model_en = os.path.join(args.model_dir,'elastic-net')\n",
    "    pickle.dump(en, open(model_en, 'wb'))\n",
    "    print('Finished training elastic net')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Train the random forest model\n",
    "    \"\"\"\n",
    "    rf_hyperparameters = {\n",
    "        'max_depth': args.max_depth\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestRegressor(**rf_hyperparameters)\n",
    "    rf.fit(X_train,y_train)\n",
    "    \n",
    "    model_rf = os.path.join(args.model_dir,'random-forest')\n",
    "    pickle.dump(rf, open(model_rf, 'wb'))\n",
    "    print('Finished training random forest')\n",
    "    \n",
    "    # Calculate validation rmse and generate weights\n",
    "    predictions = []\n",
    "    predictions.append(cat.predict(X_validation))\n",
    "\n",
    "    dval = xgboost.DMatrix(X_validation)\n",
    "    predictions.append(xgb.predict(dval))\n",
    "    \n",
    "    predictions.append(en.predict(X_validation))\n",
    "    predictions.append(rf.predict(X_validation))\n",
    "    \n",
    "    # Calculate RMSEs on validation set\n",
    "    scores = []\n",
    "    for pred in predictions:\n",
    "        scores.append(np.sqrt(mean_squared_error(y_validation,pred)))\n",
    "    print(f'Validation RMSE for Catboost: {scores[0]:.2f}, XGBoost: {scores[1]:.2f}, Elastic Net: {scores[2]:.2f}, Random Forest: {scores[3]:.2f}')\n",
    "    \n",
    "    # Calculate weights by taking reciprocals of test RMSEs\n",
    "    weights = 1 / np.array(scores)\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    # Save weights to ensemble model directory\n",
    "    weights_dir = os.path.join(args.model_dir, 'weights.json')\n",
    "    json.dump(weights.tolist(), open(weights_dir,'w'))\n",
    "    \n",
    "\n",
    "def input_fn(input_data, content_type):\n",
    "    dtype=None\n",
    "    payload = StringIO(input_data)\n",
    "    \n",
    "    return np.genfromtxt(payload, dtype=dtype, delimiter=\",\")\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    catboost_model = CatBoostRegressor()\n",
    "    catboost_model.load_model(os.path.join(model_dir, 'catboost.dump'))\n",
    "    \n",
    "    xgb = pickle.load(open(os.path.join(model_dir, 'xgboost-model'), \"rb\"))\n",
    "    en = pickle.load(open(os.path.join(model_dir, 'elastic-net'), \"rb\"))\n",
    "    rf = pickle.load(open(os.path.join(model_dir, 'random-forest'), \"rb\"))\n",
    "    \n",
    "    weights = [0.25] * 4\n",
    "    weights_path = os.path.join(model_dir, 'weights.json')\n",
    "    if os.path.isfile(weights_path):\n",
    "        weights = json.load(open(weights_path,'r'))\n",
    "    \n",
    "    all_model = [catboost_model, xgb, en, rf, weights]\n",
    "    return all_model\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    weights = model[-1]\n",
    "\n",
    "    predictions_cat = model[0].predict(input_data) * weights[0]\n",
    "\n",
    "    dtest = xgb.DMatrix(input_data)\n",
    "    predictions_xgb = model[1].predict(dtest) * weights[1]\n",
    "    \n",
    "    predictions_en = model[2].predict(input_data) * weights[2]\n",
    "    predictions_rf = model[3].predict(input_data) * weights[3]\n",
    "    \n",
    "    return np.sum(np.array([predictions_cat, predictions_xgb, predictions_en, predictions_rf]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f86f54d-d208-431f-a0ba-45eb705cad31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/requirements.txt\n",
    "pandas\n",
    "catboost\n",
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e994d2e-d9d6-4321-87ca-bfceb406ca21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "hyperparameters = {}\n",
    "\n",
    "params = {\n",
    "    \"entry_point\": \"train_inference.py\",\n",
    "    \"source_dir\": \"code\",\n",
    "    \"instance_type\": 'ml.m5.xlarge',\n",
    "    \"instance_count\": 1,\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"role\": role,\n",
    "    \"base_job_name\": \"ensemble-model\",\n",
    "    \"framework_version\": \"1.0-1\",\n",
    "    \"metric_definitions\":[\n",
    "       {'Name': 'validation:rmse', 'Regex': 'validation-rmse:(.*?);'}\n",
    "    ],\n",
    "    'output_path': S3_PATH + MODEL_PREFIX + 'ensemble'\n",
    "}\n",
    "\n",
    "estimator = SKLearn(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3fb785-42ea-4a83-8833-056e37a07367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: ensemble-20240701-11-10-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 11:10:16 Starting - Starting the training job...\n",
      "2024-07-01 11:10:35 Starting - Preparing the instances for training...\n",
      "2024-07-01 11:11:03 Downloading - Downloading input data......\n",
      "2024-07-01 11:12:14 Training - Training image download completed. Training in progress...\u001b[34m2024-07-01 11:12:24,192 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:24,195 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:24,198 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:24,213 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:24,466 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting catboost (from -r requirements.txt (line 2))\n",
      "  Downloading catboost-1.2.5-cp38-cp38-manylinux2014_x86_64.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting xgboost (from -r requirements.txt (line 3))\n",
      "  Downloading xgboost-2.1.0-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (1.24.1)\u001b[0m\n",
      "\u001b[34mCollecting graphviz (from catboost->-r requirements.txt (line 2))\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib (from catboost->-r requirements.txt (line 2))\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from catboost->-r requirements.txt (line 2)) (1.8.0)\u001b[0m\n",
      "\u001b[34mCollecting plotly (from catboost->-r requirements.txt (line 2))\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from catboost->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting contourpy>=1.0.1 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting fonttools>=4.22.0 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading fonttools-4.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "      162.2/162.2 kB 20.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting packaging>=20.0 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib->catboost->-r requirements.txt (line 2)) (10.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.3.1 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=3.2.0 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting tenacity>=6.2.0 (from plotly->catboost->-r requirements.txt (line 2))\n",
      "  Downloading tenacity-8.4.2-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading catboost-1.2.5-cp38-cp38-manylinux2014_x86_64.whl (98.2 MB)\n",
      "    98.2/98.2 MB 27.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xgboost-2.1.0-py3-none-manylinux2014_x86_64.whl (4.5 MB)\n",
      "    4.5/4.5 MB 108.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "    47.1/47.1 kB 8.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "    9.2/9.2 MB 119.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "    16.4/16.4 MB 99.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "    301.1/301.1 kB 37.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading fonttools-4.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "    4.7/4.7 MB 113.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "    1.2/1.2 MB 87.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "    54.0/54.0 kB 10.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "    103.2/103.2 kB 20.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tenacity-8.4.2-py3-none-any.whl (28 kB)\u001b[0m\n",
      "\u001b[34mDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: zipp, tenacity, pyparsing, packaging, kiwisolver, graphviz, fonttools, cycler, contourpy, xgboost, plotly, importlib-resources, matplotlib, catboost\u001b[0m\n",
      "\u001b[34mSuccessfully installed catboost-1.2.5 contourpy-1.1.1 cycler-0.12.1 fonttools-4.53.0 graphviz-0.20.3 importlib-resources-6.4.0 kiwisolver-1.4.5 matplotlib-3.7.5 packaging-24.1 plotly-5.22.0 pyparsing-3.1.2 tenacity-8.4.2 xgboost-2.1.0 zipp-3.19.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,484 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,487 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,504 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,507 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,526 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,529 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,543 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"ensemble-20240701-11-10-16\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-836402295281/ensemble-20240701-11-10-16/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_inference\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_inference.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_inference.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_inference\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-836402295281/ensemble-20240701-11-10-16/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"ensemble-20240701-11-10-16\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-836402295281/ensemble-20240701-11-10-16/source/sourcedir.tar.gz\",\"module_name\":\"train_inference\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_inference.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train_inference.py\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,545 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-07-01 11:12:40,545 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\u001b[0m\n",
      "\u001b[34mNote: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mTraining Started\u001b[0m\n",
      "\u001b[34mGot Args: Namespace(alpha=1.0, eta=0.2, max_depth=5, model_dir='/opt/ml/model', num_round=6, objective='reg:squarederror', output_data_dir='/opt/ml/output/data', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\u001b[0m\n",
      "\u001b[34mFinished training catboost\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [11:13:00] WARNING: /workspace/src/learner.cc:740: \u001b[0m\n",
      "\u001b[34mParameters: { \"num_round\" } are not used.\n",
      "  warnings.warn(smsg, UserWarning)\u001b[0m\n",
      "\u001b[34mFinished training xgboost\u001b[0m\n",
      "\u001b[34mFinished training elastic net\u001b[0m\n",
      "\u001b[34mFinished training random forest\u001b[0m\n",
      "\u001b[34mValidation RMSE for Catboost: 54.55, XGBoost: 54.27, Elastic Net: 54.44, Random Forest: 54.36\u001b[0m\n",
      "\u001b[34m2024-07-01 11:15:45,836 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-07-01 11:16:05 Uploading - Uploading generated training model\n",
      "2024-07-01 11:16:05 Completed - Training job completed\n",
      "Training seconds: 301\n",
      "Billable seconds: 301\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "# Specify training data location\n",
    "s3_train_data = S3_PATH + DATA_PREFIX + 'train.csv'\n",
    "s3_validation_data = S3_PATH + DATA_PREFIX + 'validation.csv'\n",
    "\n",
    "# generating the session.s3_input() format for fit() accepted by the sdk\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "estimator.fit(\n",
    "    inputs={\n",
    "        'train': train_data,\n",
    "        'validation': validation_data\n",
    "    },\n",
    "    job_name=\"ensemble-\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78272af4-8946-4e72-964d-f11b1ee269f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: ensemble-model-2024-06-30-19-36-24-829\n",
      "INFO:sagemaker:Creating endpoint-config with name ensemble-model-2024-06-30-19-36-24-829\n",
      "INFO:sagemaker:Creating endpoint with name ensemble-model-2024-06-30-19-36-24-829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=4096,\n",
    "    max_concurrency=1,\n",
    ")\n",
    "\n",
    "predictor = estimator.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619abc6-f4b0-4431-b645-2759bd22d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d07890a7-e68d-4b57-930f-d543e9fae623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'ensemble-model-2024-06-30-19-36-24-829'\n",
    "\n",
    "# Initialize a predictor\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "282cdf81-1dc5-4c62-93fd-2675e1c5d419",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[14.01961888060059, 6.464386136834358, 20.18643940917133, 5.616834506258041, 6.13431000677692, 10.912351542143117, 13.04572546573923, 19.169639490005743, 11.554679724879048, 11.797232157711086]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predictor.predict(\n",
    "    test_df.iloc[:10,1:].to_csv(header=False,index=False),\n",
    "    initial_args={\"ContentType\": \"text/csv\"}\n",
    ")\n",
    "pred.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05c6f7d5-b440-453a-a9d2-6c8ed4d4bd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: ensemble-model-2024-06-30-19-36-24-829\n",
      "INFO:sagemaker:Deleting endpoint with name: ensemble-model-2024-06-30-19-36-24-829\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5308c0ae-9f02-4b95-b422-c3bd1761e47a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluate_ensemble.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluate_ensemble.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import tarfile\n",
    "import json\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pathlib import Path\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_tar_path = '/opt/ml/processing/model/model.tar.gz'\n",
    "    ensemble_path = '/opt/ml/processing/ensemble'\n",
    "    model_dir = os.path.join(ensemble_path,'model')\n",
    "    with tarfile.open(model_tar_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=model_dir)\n",
    "    \n",
    "    # Load models and weights\n",
    "    model = []\n",
    "    catboost_model = CatBoostRegressor()\n",
    "    catboost_model.load_model(os.path.join(model_dir, 'catboost.dump'))\n",
    "    model.append(catboost_model)\n",
    "    \n",
    "    model.append(pickle.load(open(os.path.join(model_dir, 'xgboost-model'), \"rb\")))\n",
    "    model.append(pickle.load(open(os.path.join(model_dir, 'elastic-net'), \"rb\")))\n",
    "    model.append(pickle.load(open(os.path.join(model_dir, 'random-forest'), \"rb\")))\n",
    "    \n",
    "    weights = json.load(open(os.path.join(model_dir, 'weights.json'), 'r'))\n",
    "    \n",
    "    # Load test file    \n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    test_df = pd.read_csv(test_path + \"test.csv\", header=None)\n",
    "    X_test = test_df.iloc[:,1:].values\n",
    "    y_test = test_df.iloc[:,0].values\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    predictions = []\n",
    "    predictions.append(model[0].predict(X_test))\n",
    "\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    predictions.append(model[1].predict(dtest))\n",
    "    \n",
    "    predictions.append(model[2].predict(X_test))\n",
    "    predictions.append(model[3].predict(X_test))\n",
    "    \n",
    "    predictions.append(np.sum(np.array(predictions).T * np.array(weights),axis=1))\n",
    "    \n",
    "    # Calculate RMSEs on test set\n",
    "    scores = []\n",
    "    for pred in predictions:\n",
    "        scores.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "    print(f'Test RMSE for Catboost: {scores[0]:.2f}, XGBoost: {scores[1]:.2f}, Elastic Net: {scores[2]:.2f}, Random Forest: {scores[3]:.2f}, Ensemble model: {scores[4]:.2f}')\n",
    "    \n",
    "    # Save weights and test RMSE\n",
    "    output_dict = {\n",
    "        'test_rmse': scores\n",
    "    }\n",
    "    \n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    json.dump(output_dict, open(evaluation_path,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1182c4d-1a2a-48d2-b328-68ff05b0f34d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-836402295281/ensamble-evaluate-2024-07-01-12-15-56-950/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-836402295281/ensamble-evaluate-2024-07-01-12-15-56-950/source/runproc.sh\n",
      "INFO:sagemaker:Creating processing-job with name ensamble-evaluate-2024-07-01-12-15-56-950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............\u001b[34mFound existing installation: typing 3.7.4.3\u001b[0m\n",
      "\u001b[34mUninstalling typing-3.7.4.3:\n",
      "  Successfully uninstalled typing-3.7.4.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting catboost (from -r requirements.txt (line 2))\n",
      "  Downloading catboost-1.2.5-cp38-cp38-manylinux2014_x86_64.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting xgboost (from -r requirements.txt (line 3))\n",
      "  Downloading xgboost-2.1.0-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (1.24.1)\u001b[0m\n",
      "\u001b[34mCollecting graphviz (from catboost->-r requirements.txt (line 2))\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib (from catboost->-r requirements.txt (line 2))\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from catboost->-r requirements.txt (line 2)) (1.8.0)\u001b[0m\n",
      "\u001b[34mCollecting plotly (from catboost->-r requirements.txt (line 2))\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from catboost->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting contourpy>=1.0.1 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting fonttools>=4.22.0 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading fonttools-4.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "      162.2/162.2 kB 10.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting packaging>=20.0 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib->catboost->-r requirements.txt (line 2)) (10.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.3.1 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=3.2.0 (from matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting tenacity>=6.2.0 (from plotly->catboost->-r requirements.txt (line 2))\n",
      "  Downloading tenacity-8.4.2-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib->catboost->-r requirements.txt (line 2))\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading catboost-1.2.5-cp38-cp38-manylinux2014_x86_64.whl (98.2 MB)\n",
      "    98.2/98.2 MB 28.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xgboost-2.1.0-py3-none-manylinux2014_x86_64.whl (4.5 MB)\n",
      "    4.5/4.5 MB 115.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "    47.1/47.1 kB 8.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "    9.2/9.2 MB 120.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "    16.4/16.4 MB 80.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "    301.1/301.1 kB 29.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading fonttools-4.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "    4.7/4.7 MB 104.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "    1.2/1.2 MB 20.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "    54.0/54.0 kB 7.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "    103.2/103.2 kB 13.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tenacity-8.4.2-py3-none-any.whl (28 kB)\u001b[0m\n",
      "\u001b[34mDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: zipp, tenacity, pyparsing, packaging, kiwisolver, graphviz, fonttools, cycler, contourpy, xgboost, plotly, importlib-resources, matplotlib, catboost\u001b[0m\n",
      "\u001b[34mSuccessfully installed catboost-1.2.5 contourpy-1.1.1 cycler-0.12.1 fonttools-4.53.0 graphviz-0.20.3 importlib-resources-6.4.0 kiwisolver-1.4.5 matplotlib-3.7.5 packaging-24.1 plotly-5.22.0 pyparsing-3.1.2 tenacity-8.4.2 xgboost-2.1.0 zipp-3.19.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\u001b[0m\n",
      "\u001b[34mNote: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mTest RMSE for Catboost: 50.78, XGBoost: 50.25, Elastic Net: 50.57, Random Forest: 50.31, Ensemble model: 50.09\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "\n",
    "est_cls = sagemaker.sklearn.estimator.SKLearn\n",
    "sklearn_framework_version = \"1.0-1\"\n",
    "\n",
    "processor = FrameworkProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version=sklearn_framework_version,\n",
    "    base_job_name='ensamble-evaluate',\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "s3_test_data = S3_PATH + DATA_PREFIX + 'test.csv'\n",
    "\n",
    "processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source='s3://sagemaker-us-east-1-836402295281/GROUP6/model/ensemble/ensemble-20240701-11-10-16/output/model.tar.gz',\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=s3_test_data,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\",\n",
    "                         source=\"/opt/ml/processing/evaluation\",\n",
    "                         destination=S3_PATH + f'{GROUP_NAME}/evaluate/ensemble'\n",
    "                        ),\n",
    "    ],\n",
    "    code=\"evaluate_ensemble.py\",\n",
    "    source_dir='code'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58b875-d55f-4fc5-b2fc-744232f32e55",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240f6d0-6c0b-4a6b-b9d9-79dd362633e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Step\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version='1.2-1',\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=BASE_JOB_PROCESSING_NAME,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "process_args = sklearn_processor.run(\n",
    "    code=\"code/preprocess.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=S3_PATH + DATA_PREFIX,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"scaler_model\",\n",
    "            source=\"/opt/ml/processing/output/preprocessor\",\n",
    "            destination=S3_PATH + MODEL_PREFIX\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=S3_PATH + DATA_PREFIX\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/output/validation\",\n",
    "            destination=S3_PATH + DATA_PREFIX\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination=S3_PATH + DATA_PREFIX\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    step_args=processor_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f8b94-9b1d-4e70-9e52-b425b80ee59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and hyperparameter tuning step\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "params = {\n",
    "    \"entry_point\": \"train_inference.py\",\n",
    "    \"source_dir\": \"code\",\n",
    "    \"instance_type\": training_instance_type,\n",
    "    \"instance_count\": training_instance_type,\n",
    "    \"role\": role,\n",
    "    \"framework_version\": sklearn_framework_version,\n",
    "    \"metric_definitions\":[\n",
    "       {'Name': 'validation:rmse', 'Regex': 'validation-rmse:(.*?);'}\n",
    "    ],\n",
    "    'output_path': S3_PATH + MODEL_PREFIX + 'ensemble',\n",
    "    'base_job_name': BASE_JOB_TRAINING_NAME,\n",
    "    'sagemaker_session': pipeline_session\n",
    "}\n",
    "\n",
    "estimator = SKLearn(**params)\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_round': IntegerParameter(5,20),\n",
    "    'max_depth': IntegerParameter(5,20),\n",
    "    'eta': ContinuousParameter(0.001,0.2),\n",
    "    'alpha': ContinuousParameter(0.0,2.0)\n",
    "}\n",
    "\n",
    "metric_definitions = [{\"Name\": \"validation:rmse\", \"Regex\": \"validation-rmse:([0-9\\\\.]+)\"}]\n",
    "objective_metric_name = \"validation:rmse\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator, \n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges, \n",
    "    metric_definitions,\n",
    "    max_jobs=5, \n",
    "    max_parallel_jobs=5,\n",
    "    objective_type='Minimize'\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "tune_args = tuner.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        )\n",
    "    },\n",
    "    include_cls_metadata=False\n",
    ")\n",
    "\n",
    "step_tune_model = TuningStep(name='TuneEnsemble', step_args=tune_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eac587-055b-45a7-a43d-a5995d198cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Step\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "\n",
    "est_cls = sagemaker.sklearn.estimator.SKLearn\n",
    "\n",
    "processor = FrameworkProcessor(\n",
    "    role=role,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version=sklearn_framework_version,\n",
    "    base_job_name=BASE_JOB_EVALUATION_NAME,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "# Create a PropertyFile\n",
    "# A PropertyFile is used to be able to reference outputs from a processing step, for instance to use in a condition step.\n",
    "# For more information, visit https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "eval_args = processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tune_model.get_top_model_s3_uri(\n",
    "                top_k=0,\n",
    "                s3_bucket=bucket,\n",
    "                prefix=MODEL_PREFIX + 'ensemble'\n",
    "            ),\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"evaluate_ensemble.py\",\n",
    "    source_dir='code'\n",
    ")\n",
    "\n",
    "step_evaluate_model = ProcessingStep(\n",
    "    name=\"EvaluateModelPerformance\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29364602-a3a2-4e56-a579-239104b80f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Step\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import PipelineModel\n",
    "\n",
    "\n",
    "scaler_model_s3 = \"{}/model.tar.gz\".format(\n",
    "    step_process.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "scaler_model = SKLearnModel(\n",
    "    model_data=scaler_model_s3,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    entry_point=\"code/preprocess.py\",\n",
    "    framework_version=sklearn_framework_version,\n",
    ")\n",
    "\n",
    "scaler_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}\n",
    "\n",
    "ensemble_model = SKLearnModel(\n",
    "    model_data=step_tune_model.get_top_model_s3_uri(\n",
    "        top_k=0,\n",
    "        s3_bucket=bucket,\n",
    "        prefix=MODEL_PREFIX + 'ensemble'\n",
    "    ),\n",
    "    entry_point='train_inference.py',\n",
    "    source_dir='code'\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    models=[scaler_model, ensemble_model], role=role, sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "evaluation_s3_uri = \"{}/evaluation.json\".format(\n",
    "    step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=evaluation_s3_uri,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = pipeline_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP_NAME,\n",
    "    model_metrics=model_metrics,\n",
    "    approval_status=model_approval_status,\n",
    ")\n",
    "\n",
    "step_register_pipeline_model = ModelStep(\n",
    "    name=\"PipelineModel\",\n",
    "    step_args=register_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60603c93-6042-4c67-b50c-c7f6d6400638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition Step\n",
    "\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_model.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"test_rmse[4]\",\n",
    "    ),\n",
    "    right=accuracy_rmse_threshold,\n",
    ")\n",
    "\n",
    "# Create a Sagemaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name=\"RMSE-Lower-Than-Threshold-Condition\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register_pipeline_model],  # step_register_model, step_register_scaler,\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2801e4-ef31-4968-997c-7a554334fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Create a Sagemaker Pipeline.\n",
    "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
    "# Also pass in each of the steps created above.\n",
    "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
    "# not on the order they are passed in below.\n",
    "pipeline = Pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    parameters=[\n",
    "        training_instance_type,\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        input_data,\n",
    "        model_approval_status,\n",
    "        accuracy_rmse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_tune_model, step_evaluate_model, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8352014-f94b-4314-89ff-944d9a7e5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba20223-ca3b-4f1a-8555-7a7ef27c1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0129455-54b1-4cec-8b6e-518531bcd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
